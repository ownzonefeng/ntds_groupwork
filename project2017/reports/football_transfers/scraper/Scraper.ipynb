{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfermarkt Scraper\n",
    "\n",
    "This Notebook contains all the code required to scrape the football players informations from [Transfermarkt.com](http://transfermarkt.com).\n",
    "\n",
    "It automatically scrape infos about European, American and Asian leagues that have an estimated total market value > 200M euros. It scrapes all the clubs from thoses leagues, then download all the html pages of the players. \n",
    "\n",
    "The players page are then parsed, and a DataFrame summing up all infos about the players (Name, current club, market value, birthdate, list of transfers, etc...) is created and saved as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import *\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.transfermarkt.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseContinent(ref):\n",
    "    \n",
    "    HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "    url = base_url + \"/\" + ref\n",
    "\n",
    "    r = requests.get(url, headers=HEADERS)\n",
    "    response = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    leagues = []\n",
    "    rows = response.find(\"table\", {\"class\":\"items\"}).find_all(\"tr\",{\"class\",\"odd\"})\n",
    "    rows += response.find(\"table\", {\"class\":\"items\"}).find_all(\"tr\",{\"class\",\"even\"})\n",
    "\n",
    "    for row in rows:\n",
    "        val = row.find(\"td\",{\"class\":\"rechts hauptlink\"}).text\n",
    "        val = \".\".join(val.split(\",\"))\n",
    "        rest = val.split(\" \")[1]\n",
    "        val = val.split(\" \")[0]\n",
    "        if \"Bill\" in rest:\n",
    "            val = float(val) * 10**9\n",
    "        else:\n",
    "            if \"Mill\" in rest:\n",
    "                val = float(val) * 10**6\n",
    "            else: \n",
    "                val = 0\n",
    "        if val > 200*10**6:\n",
    "            league = {}\n",
    "            league[\"href\"] = row.findAll('a')[1]['href']\n",
    "            league[\"name\"] = row.find(\"img\")[\"title\"]\n",
    "            league[\"country\"] = row.find(\"td\",{\"class\",\"zentriert\"}).find(\"img\")[\"title\"]\n",
    "            league[\"tot_value\"] = val\n",
    "            leagues.append(league)\n",
    "            \n",
    "    return leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlayers(club_page):\n",
    "    players = []\n",
    "    players_infos = club_page.find(\"div\", {\"id\":\"yw1\"}).find(\"table\", {\"class\":\"items\"}).find(\"tbody\").find_all(\"tr\", recursive=False)\n",
    "    for player_info in players_infos:\n",
    "        player = {}\n",
    "        player_info = player_info.find(\"a\", {\"class\":\"spielprofil_tooltip\"})\n",
    "        player[\"name\"] = player_info[\"title\"]\n",
    "        player[\"id\"] = player_info[\"id\"]\n",
    "        player[\"href\"] = player_info[\"href\"]\n",
    "        players.append(player)\n",
    "    return players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leagues_clubs(league_ref): #get clubs in league\n",
    "\n",
    "    HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "    url = base_url + league_ref\n",
    "    clubs = []\n",
    "    \n",
    "    r = requests.get(url, headers=HEADERS)\n",
    "    response = BeautifulSoup(r.text, 'html.parser')\n",
    "    rows = response.find(\"table\", {\"class\":\"items\"}).find_all(\"tr\",{\"class\",\"odd\"})\n",
    "    rows += response.find(\"table\", {\"class\":\"items\"}).find_all(\"tr\",{\"class\",\"even\"})\n",
    "    \n",
    "    clubs = []\n",
    "    for row in rows:\n",
    "        try:\n",
    "            clubs.append(row.findAll(\"td\",{\"class\":\"zentriert\"})[1].find('a')['href'])\n",
    "        except:\n",
    "            None\n",
    "    \n",
    "    return clubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_league(league_ref): #get clubs in league\n",
    "\n",
    "    HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "    url = base_url + league_ref\n",
    "    clubs = []\n",
    "    \n",
    "    r = requests.get(url, headers=HEADERS)\n",
    "    response = BeautifulSoup(r.text, 'html.parser')\n",
    "    rows = response.find(\"table\", {\"class\":\"items\"}).find_all(\"tr\",{\"class\",\"odd\"})\n",
    "    rows += response.find(\"table\", {\"class\":\"items\"}).find_all(\"tr\",{\"class\",\"even\"})\n",
    "    \n",
    "    for row in rows:\n",
    "            \n",
    "            url_club = base_url + row.findAll(\"td\",{\"class\":\"zentriert\"})[1].find('a')['href']\n",
    "            r_club = requests.get(url_club, headers=HEADERS)\n",
    "            response_club = BeautifulSoup(r_club.text, 'html.parser')\n",
    "            stadium_info =response_club.find(\"div\",{\"id\":\"main\"}).findAll(\"span\",{\"class\":\"dataValue\"})[4].text\n",
    "            \n",
    "            stadium_info=stadium_info.replace(u'\\xa0',u'')\n",
    "            stadium_info=stadium_info.replace(u'\\n',u'')\n",
    "\n",
    "\n",
    "            split_stadium= re.split(r'(\\d+)',stadium_info)\n",
    "            stadium = split_stadium[0]\n",
    "#             num_seats = float(split_stadium[1]+'.'+split_stadium[3])\n",
    "           \n",
    "            \n",
    "            club = {}\n",
    "            club[\"name\"] = row.findAll(\"td\",{\"class\":\"zentriert\"})[1].find('a')['title']\n",
    "            club[\"href\"] = row.findAll(\"td\",{\"class\":\"zentriert\"})[1].find('a')['href']\n",
    "            club[\"squad\"] = row.findAll(\"td\",{\"class\":\"zentriert\"})[1].text\n",
    "            club[\"market_value\"] = row.find(\"td\",{\"class\":\"rechts show-for-small show-for-pad nowrap\"}).text\n",
    "            club[\"stadium\"] = stadium\n",
    "            \n",
    "            players = getPlayers(BeautifulSoup(r_club.text, 'html.parser'))\n",
    "            club[\"players\"] = players\n",
    "#             club[\"stadium_seats\"] = num_seats\n",
    "            clubs.append(club)  \n",
    "    \n",
    "    return clubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlayersPage(player_ref):\n",
    "        \n",
    "    HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "    url = base_url + player_ref\n",
    "\n",
    "    r = requests.get(url, headers=HEADERS)\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nleagues = parseContinent(\"wettbewerbe/europa\")\\nleagues += parseContinent(\"wettbewerbe/amerika\")\\nleagues += parseContinent(\"wettbewerbe/asien\")\\nwith open(\"data/leagues.json\", \"w\") as out:\\n    json.dump(leagues, out)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "leagues = parseContinent(\"wettbewerbe/europa\")\n",
    "leagues += parseContinent(\"wettbewerbe/amerika\")\n",
    "leagues += parseContinent(\"wettbewerbe/asien\")\n",
    "with open(\"data/leagues.json\", \"w\") as out:\n",
    "    json.dump(leagues, out)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leagues: 25\n",
      "Premier League\n",
      "Serie A\n",
      "Ligue 1\n",
      "Liga NOS\n",
      "Eredivisie\n",
      "Super League\n",
      "Raiffeisen Super League\n",
      "LaLiga\n",
      "1.Bundesliga\n",
      "Süper Lig\n",
      "Premier Liga\n",
      "Jupiler Pro League\n",
      "Premier Liga\n",
      "HET Liga\n",
      "Campeonato Brasileiro Série A\n",
      "Liga MX Clausura\n",
      "Major League Soccer\n",
      "Copa MX Clausura\n",
      "Primera División\n",
      "Liga MX Apertura\n",
      "Liga Águila I\n",
      "Copa MX Apertura\n",
      "Liguilla Apertura\n",
      "Chinese Super League\n",
      "J1 League\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/leagues.json\", \"r\") as in_file:\n",
    "    leagues = json.load(in_file)\n",
    "    \n",
    "print(\"Number of leagues: \" + str(len(leagues)))\n",
    "for league in leagues:\n",
    "    print(league[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nleaguesData = []\\nfor league in leagues:\\n    leaguesData.append(get_leagues_clubs(league[\\'href\\']))\\n    \\nclub_leagues = {}\\nfor i in range(len(leagues)):\\n    for club in leaguesData[i]:\\n        club_leagues[club.split(\"/\")[4]] = leagues[i][\"name\"]\\n        \\nwith open(\"data/clubs_leauges.json\", \"w\") as out:\\n    json.dump(club_leagues, out)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "leaguesData = []\n",
    "for league in leagues:\n",
    "    leaguesData.append(get_leagues_clubs(league['href']))\n",
    "    \n",
    "club_leagues = {}\n",
    "for i in range(len(leagues)):\n",
    "    for club in leaguesData[i]:\n",
    "        club_leagues[club.split(\"/\")[4]] = leagues[i][\"name\"]\n",
    "        \n",
    "with open(\"data/clubs_leauges.json\", \"w\") as out:\n",
    "    json.dump(club_leagues, out)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nleaguesData = []\\nclubs = []\\nfor league in leagues:\\n    clubs += parse_league(league[\"href\"])\\n\\nwith open(\"data/clubs.json\", \"w\") as out:\\n    json.dump(clubs, out)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "leaguesData = []\n",
    "clubs = []\n",
    "for league in leagues:\n",
    "    clubs += parse_league(league[\"href\"])\n",
    "\n",
    "with open(\"data/clubs.json\", \"w\") as out:\n",
    "    json.dump(clubs, out)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/clubs.json\", \"r\") as in_file:\n",
    "    clubs = json.load(in_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean redundant clubs\n",
    "\n",
    "There are 2 Mexican leagues with redundant clubs, we keep them each once only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clubDict = {}\n",
    "for club in clubs:\n",
    "    club_id = club[\"href\"].split(\"/\")[4]\n",
    "    if club_id not in clubDict:\n",
    "        clubDict[club_id] = club\n",
    "        \n",
    "with open(\"../scraper/data/dictClubs.json\", \"w\") as out:\n",
    "    json.dump(clubDict, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../scraper/data/dictClubs.json\", \"r\") as in_file:\n",
    "    clubDict = json.load(in_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create players list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplayer_list = []\\n\\nfor club in clubs:\\n    players = club[\"players\"]\\n    for player in players:\\n        player_list.append(player[\"href\"])\\n\\nwith open(\"data/players_ref.json\", \"w\") as out:\\n    json.dump(player_list, out)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "player_list = []\n",
    "\n",
    "for club in clubs:\n",
    "    players = club[\"players\"]\n",
    "    for player in players:\n",
    "        player_list.append(player[\"href\"])\n",
    "\n",
    "with open(\"data/players_ref.json\", \"w\") as out:\n",
    "    json.dump(player_list, out)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/players_ref.json\", \"r\") as in_file:\n",
    "    players_list = json.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pages of all the players and store it in a file\n",
    "for player_ref in players_list:\n",
    "    player_id = player_ref.split(\"/\")[-1]\n",
    "     \n",
    "    directory = 'data/players/' + player_id + \"/\"\n",
    "    fname = directory + \"page.html\"\n",
    "\n",
    "    if os.path.isfile(fname) == False:\n",
    "        if os.path.exists(directory) == False:\n",
    "            os.makedirs(directory)\n",
    "        page = getPlayersPage(player_ref)\n",
    "        with open(fname, \"w\")as out:\n",
    "            json.dump(page, out)  \n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating players dataset\n",
    "\n",
    "Now that all players pages have been scraped, we can load them, parse them and extract all necessary informations. We then save the DataFrame produced as a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/players_ref.json\", \"r\") as in_file:\n",
    "    players_ref_list = json.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define method to parse player given player url\n",
    "def getPlayerData(player_ref):    \n",
    "    playerID = player_ref.split(\"/\")[-1]\n",
    "    \n",
    "    with open(\"data/players/\" + playerID + \"/page.html\") as in_file:\n",
    "        player_page = json.load(in_file)\n",
    "    \n",
    "    response = BeautifulSoup(player_page, 'html.parser')\n",
    "    \n",
    "    playerInfos = str(response.find(\"table\", {\"class\":\"auflistung\"}))\n",
    "    player = {}\n",
    "    player[\"href\"] = player_ref\n",
    "    try:\n",
    "        player[\"number\"] = response.find(\"span\", {\"class\":\"dataRN\"}).text\n",
    "    except:\n",
    "        player[\"number\"] = None\n",
    "    player[\"name\"] = response.find(\"h1\", {\"itemprop\":\"name\"}).text\n",
    "    player[\"player_id\"] = player_ref.split(\"/\")[-1]\n",
    "    position = BeautifulSoup(playerInfos.split(\"Position\")[1], 'html.parser').find(\"td\").text\n",
    "    reg = re.compile( \"[a-zA-Z -]\")\n",
    "    player[\"position\"] = \"\".join(reg.findall(position))\n",
    "    try:\n",
    "        player[\"birthdate\"] = BeautifulSoup(playerInfos.split(\"Date of birth\")[1], 'html.parser').find(\"td\").text\n",
    "    except:\n",
    "        player[\"birthdate\"] = None\n",
    "    player[\"nationality\"] = BeautifulSoup(playerInfos.split(\"Nationality\")[1], 'html.parser').find(\"td\").find(\"img\")[\"title\"]\n",
    "    player[\"current_club\"] = BeautifulSoup(playerInfos.split(\"Current club\")[1], 'html.parser').find(\"td\").find_all(\"a\")[-1].text\n",
    "\n",
    "    try:\n",
    "        transfers = []\n",
    "        trans = response.find(\"div\",{\"class\" : \"box transferhistorie\"}).find(\"table\").find(\"tbody\").find_all(\"tr\", {\"class\":\"zeile-transfer\"})\n",
    "\n",
    "        for t in trans:\n",
    "            transfer = {}\n",
    "            transfer[\"player\"] = player_ref.split(\"/\")[-1]\n",
    "            transfer[\"date\"] = t.find_all(\"td\", {\"class\":\"zentriert hide-for-small\"})[1].text\n",
    "            transfer[\"from\"] = t.find_all(\"td\", {\"class\":\"no-border-rechts vereinswappen\"})[0].find(\"a\")[\"id\"]\n",
    "            transfer[\"to\"] = t.find_all(\"td\", {\"class\":\"no-border-rechts vereinswappen\"})[1].find(\"a\")[\"id\"]\n",
    "            if (t.find(\"td\", {\"class\":\"zelle-abloese\"}).text) == \"End of loan\" or t.find(\"td\", {\"class\":\"zelle-abloese\"}).text ==\"Loan\":\n",
    "                transfer[\"fee\"] = t.find(\"td\", {\"class\":\"zelle-mw\"}).text\n",
    "            else:\n",
    "                transfer[\"fee\"] = t.find(\"td\",{\"class\":\"zelle-abloese\"}).text\n",
    "                        \n",
    "            transfers.append(transfer)\n",
    "    except:\n",
    "        transfers = None\n",
    "        \n",
    "    return player, transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the amount of the transfer as an int from a string\n",
    "def getTransferAmount(fee):\n",
    "    try:\n",
    "        if fee == \"-\" or fee == \"?\" or fee == \"draft\":\n",
    "            return 0\n",
    "        if \"free\" in fee or \"Free\" in fee:\n",
    "            return 0\n",
    "        if fee is not None:\n",
    "            val = \".\".join(fee.split(\",\"))\n",
    "            rest = val.split(\" \")[1]\n",
    "            val = val.split(\" \")[0]\n",
    "\n",
    "            if \"Mill\" in rest:\n",
    "                return float(val) * 10**6\n",
    "            else:\n",
    "                if \"Th\" in rest: \n",
    "                    return float(val) * 10**3\n",
    "                else:\n",
    "                    return 0\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads each player, parse the page to retrieve infos, then compute the amont of the transfer from the strings\n",
    "# and save the whole DataFrame as a JSON file\n",
    "players_data = []\n",
    "players_transfers = []\n",
    "for player_id in players_ref_list:\n",
    "    player = getPlayerData(player_id)\n",
    "    print(player)\n",
    "    players_data.append(player[0])\n",
    "    players_transfers.append(player[1])\n",
    "    \n",
    "playersDF = pd.DataFrame(players_data)\n",
    "playersDF[\"transfers\"] = players_transfers\n",
    "\n",
    "# Convert string fees to integers\n",
    "for idx, player in playersDF.iterrows():\n",
    "    if player[\"transfers\"] is not None:\n",
    "        for transfer in player[\"transfers\"]:\n",
    "            transfer[\"amount\"] = getTransferAmount(transfer[\"fee\"])\n",
    "\n",
    "playersDF.to_json(\"data/players.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "playersDF = pd.read_json(\"data/players.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of players: 12075\n",
      "Total number of transfers: 73558\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of players: \" + str(len(playersDF)))\n",
    "print(\"Total number of transfers: \" + str(playersDF[\"transfers\"].map(lambda x: len(x) if x is not None else 0).sum()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
